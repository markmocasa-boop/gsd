---
phase: 02-data-quality-ai-recommendations
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - agents/dq_recommender/agent.py
  - agents/dq_recommender/tools/rule_generator.py
  - agents/dq_recommender/tools/glue_recommender.py
  - agents/dq_recommender/tools/template_library.py
  - agents/dq_recommender/tools/remediation.py
  - agents/dq_recommender/schemas.py
  - agents/dq_recommender/prompts.py
  - agents/dq_recommender/requirements.txt
  - supabase/migrations/002_dq_rules.sql
  - lambdas/approval_handler/handler.py
  - lambdas/approval_handler/requirements.txt
  - infra/lib/dq-recommender-stack.ts
autonomous: true

must_haves:
  truths:
    - "DQ Recommender agent can generate DQDL rules from natural language descriptions"
    - "Agent provides reasoning explaining why each rule is suggested"
    - "Industry-standard rule templates can be applied to columns"
    - "AI-generated rules require human approval before activation"
  artifacts:
    - path: "agents/dq_recommender/agent.py"
      provides: "Strands DQ Recommender agent with rule generation tools"
      exports: ["dq_recommender_agent"]
    - path: "agents/dq_recommender/tools/rule_generator.py"
      provides: "Natural language to DQDL rule generation"
      exports: ["generate_dqdl_rule"]
    - path: "agents/dq_recommender/tools/template_library.py"
      provides: "Pre-defined industry rule templates"
      exports: ["apply_rule_template", "list_templates"]
    - path: "supabase/migrations/002_dq_rules.sql"
      provides: "Database schema for DQ rules and approval workflow"
      contains: "CREATE TABLE dq_rules"
    - path: "lambdas/approval_handler/handler.py"
      provides: "Human approval webhook for Step Functions"
      exports: ["handler"]
  key_links:
    - from: "agents/dq_recommender/agent.py"
      to: "tools/rule_generator.py"
      via: "Strands @tool registration"
      pattern: "tools=\\[generate_dqdl_rule"
    - from: "agents/dq_recommender/tools/rule_generator.py"
      to: "Amazon Bedrock"
      via: "Converse API for rule generation"
      pattern: "bedrock.*converse"
    - from: "lambdas/approval_handler/handler.py"
      to: "Step Functions"
      via: "send_task_success/send_task_failure"
      pattern: "sfn\\.send_task_success|sfn\\.send_task_failure"
---

<objective>
Build the DQ Recommender Agent that generates data quality rules from natural language with human-in-the-loop approval.

Purpose: Enable users to describe quality rules in natural language and receive generated DQDL validation code with AI-provided reasoning. This is the core AI differentiator that reduces rule creation from 9 minutes to 1 minute per rule.

Output: Functional DQ Recommender agent, rule database schema, and approval workflow Lambda.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/02-data-quality-ai-recommendations/02-RESEARCH.md
@.planning/phases/01-foundation-data-profiling/01-01-SUMMARY.md
@.planning/phases/01-foundation-data-profiling/01-02-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: DQ Recommender Agent with Tools</name>
  <files>
    agents/dq_recommender/agent.py
    agents/dq_recommender/tools/rule_generator.py
    agents/dq_recommender/tools/glue_recommender.py
    agents/dq_recommender/tools/template_library.py
    agents/dq_recommender/tools/remediation.py
    agents/dq_recommender/schemas.py
    agents/dq_recommender/prompts.py
    agents/dq_recommender/requirements.txt
    agents/dq_recommender/__init__.py
    agents/dq_recommender/tools/__init__.py
  </files>
  <action>
    Implement the DQ Recommender Agent using Strands Agents SDK following research patterns:

    **schemas.py:**
    - Pydantic models for rule definitions:
      - `RuleType` enum: completeness, uniqueness, range, pattern, freshness, referential, custom
      - `Severity` enum: critical, warning, info
      - `RuleStatus` enum: pending, approved, active, disabled, deprecated
      - `DQRule`: id, dataset_id, column_name, rule_type, dqdl_expression, description, reasoning, severity, status
      - `RuleGenerationRequest`: description (natural language), column_name, profile_summary (JSON)
      - `RuleGenerationResponse`: rule, reasoning, false_positive_scenarios, severity

    **prompts.py:**
    - System prompt for DQ Recommender agent (copy from research, customize for project context)
    - Include DQDL syntax reference, rule type examples, reasoning format requirements

    **tools/rule_generator.py:**
    - `@tool` decorated function `generate_dqdl_rule(description: str, column_name: str, profile_summary: str) -> str`:
      - Uses Bedrock Converse API directly (anthropic.claude-sonnet-4-20250514)
      - Sends natural language description + profile context
      - Returns JSON with: rule (DQDL syntax), reasoning (explanation), false_positive_scenarios, severity
      - Temperature 0.2 for consistent output
      - Include DQDL syntax reference in prompt

    **tools/glue_recommender.py:**
    - `@tool` decorated function `get_glue_recommendations(database: str, table: str, catalog_id: str = None) -> str`:
      - Calls boto3 glue client start_data_quality_rule_recommendation_run
      - Returns JSON with recommended DQDL rules from AWS ML
      - Handle async polling (simplified for tool context - just return run_id)
    - Helper function `check_recommendation_status(run_id: str) -> dict`:
      - Gets recommendation run results when complete

    **tools/template_library.py:**
    - Define RULE_TEMPLATES dict with templates from research:
      - email_validity, date_format_iso, positive_number, percentage_range
      - currency_precision, phone_us, ssn_format, uuid_format
      - not_null, unique_values, referential_integrity (parameterized)
    - `@tool` decorated function `apply_rule_template(template_name: str, column_name: str, parameters: str = "{}") -> str`:
      - Applies template with column and parameters
      - Returns JSON with template name, generated DQDL rule, column
    - `@tool` decorated function `list_templates(category: str = None) -> str`:
      - Returns available templates, optionally filtered by category (format, range, consistency, compliance)

    **tools/remediation.py:**
    - `@tool` decorated function `suggest_remediation(issue_type: str, column_name: str, issue_details: str) -> str`:
      - Maps issue types to remediation suggestions (from research)
      - Issue types: null_values, out_of_range, format_mismatch, duplicate_values, referential_integrity
      - Returns JSON with suggestions list and priority

    **agent.py:**
    - Import BedrockModel from strands.models.bedrock
    - Configure model: anthropic.claude-sonnet-4-20250514, us-east-1, temperature=0.2
    - Define dq_recommender_agent with system prompt from prompts.py
    - Register tools: [generate_dqdl_rule, get_glue_recommendations, apply_rule_template, list_templates, suggest_remediation]

    **requirements.txt:**
    ```
    strands-agents>=1.0.0
    boto3>=1.35.0
    pydantic>=2.0.0
    ```
  </action>
  <verify>
    cd agents/dq_recommender && python -c "
from agent import dq_recommender_agent
from tools.rule_generator import generate_dqdl_rule
from tools.template_library import apply_rule_template, list_templates
from tools.remediation import suggest_remediation
print('Agent and tools imported successfully')
print(f'Tools registered: {len(dq_recommender_agent.tools)}')"
  </verify>
  <done>
    DQ Recommender agent imports with 5 tools registered. Rule generator uses Bedrock Converse API. Templates cover common patterns. Remediation suggestions match issue types.
  </done>
</task>

<task type="auto">
  <name>Task 2: Database Schema and Approval Lambda</name>
  <files>
    supabase/migrations/002_dq_rules.sql
    lambdas/approval_handler/handler.py
    lambdas/approval_handler/requirements.txt
    infra/lib/dq-recommender-stack.ts
  </files>
  <action>
    Create database schema for rules and approval workflow infrastructure:

    **supabase/migrations/002_dq_rules.sql:**
    Create tables following research schema (adapted for existing Phase 1 tables):

    1. `dq_rules` - Quality rule definitions:
       - id UUID PK, dataset_id FK references datasets(id) ON DELETE CASCADE
       - column_name VARCHAR(255) (NULL for table-level rules)
       - rule_type VARCHAR(50) NOT NULL, dqdl_expression TEXT NOT NULL, description TEXT
       - generated_by VARCHAR(50), reasoning TEXT, template_name VARCHAR(100)
       - status VARCHAR(20) DEFAULT 'pending', severity VARCHAR(20) DEFAULT 'warning'
       - created_by UUID, approved_by UUID, owner_id UUID (FK to auth.users if exists, else leave without FK)
       - expires_at TIMESTAMPTZ, last_triggered_at TIMESTAMPTZ, trigger_count INTEGER DEFAULT 0
       - created_at, updated_at TIMESTAMPTZ

    2. `rule_templates` - Pre-defined templates:
       - id UUID PK, name VARCHAR(100) NOT NULL UNIQUE
       - category VARCHAR(50), description TEXT
       - dqdl_pattern TEXT NOT NULL, parameters JSONB
       - industry_standards JSONB
       - created_at TIMESTAMPTZ

    3. `rule_approval_requests` - Approval workflow tracking:
       - id UUID PK, rule_id FK references dq_rules(id)
       - task_token TEXT (Step Functions callback token)
       - requested_at TIMESTAMPTZ, expires_at TIMESTAMPTZ
       - status VARCHAR(20) DEFAULT 'pending' (pending, approved, rejected, expired)
       - reviewed_by UUID, reviewed_at TIMESTAMPTZ, comments TEXT
       - created_at TIMESTAMPTZ

    **Indexes:** rules by dataset_id, rules by status, approvals by status
    **RLS:** Enable on all tables, SELECT for authenticated, INSERT/UPDATE for authenticated

    Seed initial rule_templates from template_library.py patterns.

    **lambdas/approval_handler/handler.py:**
    Create Lambda for processing human approvals (from research patterns):
    - Parse event body: taskToken, approved (bool), reviewer, comments
    - If approved:
      - Update dq_rules status to 'approved', approved_by, updated_at
      - Update rule_approval_requests status, reviewed_by, reviewed_at, comments
      - Call sfn.send_task_success with approval details
    - If rejected:
      - Update dq_rules status to 'rejected'
      - Update rule_approval_requests
      - Call sfn.send_task_failure with rejection reason
    - Return 200 with status

    **lambdas/approval_handler/requirements.txt:**
    ```
    boto3>=1.35.0
    aws-lambda-powertools>=3.0.0
    ```

    **infra/lib/dq-recommender-stack.ts:**
    Create CDK stack for DQ Recommender infrastructure:
    - Lambda function for approval_handler:
      - Runtime: Python 3.11
      - Timeout: 30 seconds
      - Environment: SUPABASE_URL, SUPABASE_KEY from Secrets Manager
      - IAM: states:SendTaskSuccess, states:SendTaskFailure
    - API Gateway HTTP endpoint for approval webhook:
      - POST /approvals -> approval_handler Lambda
      - CORS enabled for frontend
    - Export Lambda ARN and API endpoint URL
  </action>
  <verify>
    # Validate SQL syntax
    cat supabase/migrations/002_dq_rules.sql | grep -E "CREATE TABLE|CREATE INDEX" | wc -l
    # Should show 3 tables, 3+ indexes

    # Check Lambda handler
    python -c "import lambdas.approval_handler.handler" 2>&1 || echo "Lambda imports need AWS context"

    # CDK synth
    cd infra && npx cdk synth --quiet
  </verify>
  <done>
    Migration file contains dq_rules, rule_templates, rule_approval_requests tables. Approval Lambda handles Step Functions callbacks. CDK stack defines Lambda and API Gateway.
  </done>
</task>

</tasks>

<verification>
1. `cd agents/dq_recommender && python -c "from agent import dq_recommender_agent"` succeeds
2. SQL migration has valid syntax with 3 tables
3. Approval Lambda handler has correct Step Functions integration
4. CDK synthesizes with Lambda and API Gateway resources
5. All tool functions follow research patterns for DQDL generation
</verification>

<success_criteria>
- DQ Recommender agent uses Strands SDK with 5 tools (rule_generator, glue_recommender, template_library with 2 functions, remediation)
- Rule generator uses Bedrock Converse API with DQDL syntax reference
- Template library includes 8+ industry-standard patterns
- Remediation suggestions cover 5 issue types with actionable recommendations
- Database schema stores rules with approval workflow metadata
- Approval Lambda correctly signals Step Functions success/failure
- All AI-generated rules start in 'pending' status requiring approval
</success_criteria>

<output>
After completion, create `.planning/phases/02-data-quality-ai-recommendations/02-01-SUMMARY.md`
</output>
