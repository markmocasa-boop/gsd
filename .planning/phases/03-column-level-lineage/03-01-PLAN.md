---
phase: 03-column-level-lineage
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - supabase/migrations/004_lineage_schema.sql
  - agents/lineage/agent.py
  - agents/lineage/schemas.py
  - agents/lineage/prompts.py
  - agents/lineage/tools/sql_parser.py
  - agents/lineage/tools/openlineage.py
  - agents/lineage/tools/impact_analyzer.py
  - agents/lineage/tools/__init__.py
  - agents/lineage/__init__.py
  - agents/lineage/requirements.txt
autonomous: true

must_haves:
  truths:
    - "Lineage agent can parse SQL queries and extract column-level dependencies"
    - "System stores lineage as traversable graph with nodes and edges"
    - "User can query downstream impact of a column change"
    - "User can query upstream root cause of a column"
    - "System produces OpenLineage-compatible events"
  artifacts:
    - path: "supabase/migrations/004_lineage_schema.sql"
      provides: "Graph storage schema for lineage nodes and edges"
      contains: "CREATE TABLE lineage_nodes"
    - path: "agents/lineage/agent.py"
      provides: "Strands Lineage agent with analysis tools"
      exports: ["lineage_agent"]
    - path: "agents/lineage/tools/sql_parser.py"
      provides: "SQLGlot-based column lineage extraction from SQL"
      exports: ["parse_sql_lineage", "extract_column_dependencies"]
    - path: "agents/lineage/tools/openlineage.py"
      provides: "OpenLineage event creation and emission"
      exports: ["create_lineage_event", "emit_openlineage_event"]
    - path: "agents/lineage/tools/impact_analyzer.py"
      provides: "Upstream/downstream graph traversal"
      exports: ["get_downstream_impact", "get_upstream_sources"]
  key_links:
    - from: "agents/lineage/agent.py"
      to: "tools/sql_parser.py"
      via: "Strands @tool registration"
      pattern: "tools=\\[parse_sql_lineage"
    - from: "agents/lineage/tools/sql_parser.py"
      to: "SQLGlot library"
      via: "lineage extraction"
      pattern: "sqlglot\\.lineage"
    - from: "agents/lineage/tools/impact_analyzer.py"
      to: "Supabase/PostgreSQL"
      via: "recursive CTE for graph traversal"
      pattern: "WITH RECURSIVE downstream"
---

<objective>
Build the Lineage Agent core with database schema for graph storage, SQLGlot-based SQL parsing, OpenLineage event production, and impact analysis tools.

Purpose: Enable column-level lineage tracking by storing lineage as a graph, parsing SQL to extract dependencies, and providing traversal for impact analysis. This is the foundation that extraction and visualization depend on.

Output: Functional Lineage agent, database schema for lineage graph, SQL parsing tools, and impact analysis queries.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/03-column-level-lineage/03-RESEARCH.md
@.planning/phases/01-foundation-data-profiling/01-01-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Lineage Database Schema</name>
  <files>
    supabase/migrations/004_lineage_schema.sql
  </files>
  <action>
    Create database schema for lineage graph storage following research patterns:

    **Table 1: lineage_nodes**
    Represents datasets, columns, and jobs in the lineage graph:
    - id UUID PK DEFAULT gen_random_uuid()
    - node_type VARCHAR(20) NOT NULL (dataset, column, job)
    - namespace VARCHAR(500) NOT NULL (e.g., redshift://analytics, s3://bucket)
    - name VARCHAR(255) NOT NULL (table name for dataset, column name for column)
    - parent_id UUID REFERENCES lineage_nodes(id) ON DELETE CASCADE (column -> dataset relationship)
    - data_type VARCHAR(100) (for columns: INT, VARCHAR, etc.)
    - metadata JSONB (flexible storage for additional properties)
    - created_at TIMESTAMPTZ DEFAULT NOW()
    - updated_at TIMESTAMPTZ DEFAULT NOW()
    - UNIQUE(node_type, namespace, name, parent_id)

    **Table 2: lineage_edges**
    Represents data flow between nodes:
    - id UUID PK DEFAULT gen_random_uuid()
    - source_id UUID NOT NULL REFERENCES lineage_nodes(id) ON DELETE CASCADE
    - target_id UUID NOT NULL REFERENCES lineage_nodes(id) ON DELETE CASCADE
    - edge_type VARCHAR(50) NOT NULL (derives_from, transforms_to)
    - transformation_type VARCHAR(50) (DIRECT, INDIRECT from OpenLineage)
    - transformation_subtype VARCHAR(50) (IDENTITY, TRANSFORMATION, AGGREGATION, JOIN, FILTER, etc.)
    - transformation_description TEXT
    - job_id UUID REFERENCES lineage_nodes(id) ON DELETE SET NULL
    - sql_hash VARCHAR(64) (hash of SQL that created this edge)
    - created_at TIMESTAMPTZ DEFAULT NOW()
    - UNIQUE(source_id, target_id, job_id)

    **Table 3: lineage_runs**
    Tracks lineage extraction jobs:
    - id UUID PK DEFAULT gen_random_uuid()
    - source_type VARCHAR(50) NOT NULL (redshift, athena, glue, manual)
    - status VARCHAR(20) NOT NULL DEFAULT 'pending' (pending, running, completed, failed)
    - started_at TIMESTAMPTZ
    - completed_at TIMESTAMPTZ
    - queries_processed INTEGER DEFAULT 0
    - edges_created INTEGER DEFAULT 0
    - error_message TEXT
    - created_at TIMESTAMPTZ DEFAULT NOW()

    **Indexes:**
    - lineage_nodes: (node_type), (namespace), (parent_id), (node_type, namespace, name)
    - lineage_edges: (source_id), (target_id), (source_id, target_id), (job_id)
    - lineage_runs: (status), (source_type), (created_at DESC)

    **RLS:** Enable on all tables with policies for authenticated users (SELECT, INSERT, UPDATE, DELETE).

    **Add helper functions for graph traversal:**
    - Function: get_downstream_nodes(column_id UUID, max_depth INT DEFAULT 10)
      Returns TABLE(id UUID, node_type VARCHAR, namespace VARCHAR, name VARCHAR, depth INT)
      Uses recursive CTE with cycle detection
    - Function: get_upstream_nodes(column_id UUID, max_depth INT DEFAULT 10)
      Similar but traverses edges in reverse direction
  </action>
  <verify>
    # Validate SQL syntax
    cat supabase/migrations/004_lineage_schema.sql | grep -E "CREATE TABLE|CREATE FUNCTION" | wc -l
    # Should show 3 tables + 2 functions = 5+
  </verify>
  <done>
    Migration file contains lineage_nodes, lineage_edges, lineage_runs tables with proper indexes, RLS policies, and two recursive traversal functions.
  </done>
</task>

<task type="auto">
  <name>Task 2: Lineage Agent with SQL Parser and Impact Analyzer</name>
  <files>
    agents/lineage/agent.py
    agents/lineage/schemas.py
    agents/lineage/prompts.py
    agents/lineage/tools/sql_parser.py
    agents/lineage/tools/openlineage.py
    agents/lineage/tools/impact_analyzer.py
    agents/lineage/tools/__init__.py
    agents/lineage/__init__.py
    agents/lineage/requirements.txt
  </files>
  <action>
    Implement the Lineage Agent using Strands Agents SDK following established profiler/dq_recommender patterns:

    **schemas.py:**
    Pydantic models for lineage data:
    - `NodeType` enum: dataset, column, job
    - `EdgeType` enum: derives_from, transforms_to
    - `TransformationType` enum: DIRECT, INDIRECT
    - `TransformationSubtype` enum: IDENTITY, TRANSFORMATION, AGGREGATION, JOIN, GROUP_BY, FILTER, SORT, WINDOW, CONDITIONAL
    - `LineageNode`: id, node_type, namespace, name, parent_id, data_type, metadata
    - `LineageEdge`: id, source_id, target_id, edge_type, transformation_type, transformation_subtype, description, job_id
    - `ColumnLineage`: column, source_columns (list), transformation_description
    - `SQLLineageResult`: sql_hash, source_tables, target_table, column_lineages (list[ColumnLineage])
    - `ImpactResult`: root_node, affected_nodes (list with depth), total_count

    **prompts.py:**
    System prompt for Lineage agent:
    - Explain agent capabilities: parse SQL, extract lineage, analyze impact
    - Reference OpenLineage transformation types
    - Provide examples of lineage queries
    - Include instructions for impact analysis interpretation

    **tools/sql_parser.py:**
    - `parse_sql_lineage(sql: str, dialect: str = "redshift", schema: str = "{}") -> str`:
      - Parse SQL using sqlglot.lineage() with provided schema context
      - Extract column-level dependencies for each output column
      - Return JSON with SQLLineageResult structure
      - Handle CTEs, subqueries, JOINs, window functions
      - Generate sql_hash for deduplication
      - Dialect options: redshift, athena, postgres, presto
    - `extract_column_dependencies(sql: str, target_column: str, dialect: str = "redshift", schema: str = "{}") -> str`:
      - Get lineage for specific output column only
      - Return JSON with column name and list of source columns with transformations

    **tools/openlineage.py:**
    - `create_lineage_event(job_name: str, inputs: str, outputs: str, column_lineage: str) -> str`:
      - Create OpenLineage RunEvent with ColumnLineageDatasetFacet
      - Producer: "https://data-foundations/lineage-agent"
      - Schema URL: "https://openlineage.io/spec/facets/1-2-0/ColumnLineageDatasetFacet.json"
      - Return JSON representation of event
    - `emit_openlineage_event(event_json: str, endpoint_url: str = None) -> str`:
      - Send event to OpenLineage backend (uses OPENLINEAGE_URL env var if not specified)
      - Return status and run_id
      - Handle connection errors gracefully

    **tools/impact_analyzer.py:**
    - `get_downstream_impact(column_id: str, max_depth: int = 10) -> str`:
      - Call Supabase RPC for get_downstream_nodes function
      - Return JSON with affected nodes, grouped by depth level
      - Include transformation type for each edge traversed
    - `get_upstream_sources(column_id: str, max_depth: int = 10) -> str`:
      - Call Supabase RPC for get_upstream_nodes function
      - Return JSON with source nodes, grouped by depth level
      - Useful for root cause analysis
    - `find_column_by_name(namespace: str, table_name: str, column_name: str) -> str`:
      - Lookup column node ID by name for use with impact functions
      - Return column node or error if not found

    **agent.py:**
    - Import BedrockModel from strands.models.bedrock
    - Configure model: anthropic.claude-sonnet-4-20250514, us-east-1, temperature=0.3
    - Define lineage_agent with system prompt from prompts.py
    - Register tools: [parse_sql_lineage, extract_column_dependencies, create_lineage_event, emit_openlineage_event, get_downstream_impact, get_upstream_sources, find_column_by_name]
    - Use LineageAgentProxy pattern for lazy loading (match profiler pattern)

    **requirements.txt:**
    ```
    strands-agents>=1.0.0
    boto3>=1.35.0
    pydantic>=2.0.0
    sqlglot>=26.0.0
    openlineage-python>=1.25.0
    ```

    **__init__.py files:**
    - agents/lineage/__init__.py: export lineage_agent, create_lineage_agent
    - agents/lineage/tools/__init__.py: export all tool functions
  </action>
  <verify>
    cd agents/lineage && python -c "
from schemas import LineageNode, LineageEdge, ColumnLineage, SQLLineageResult
from tools.sql_parser import parse_sql_lineage
from tools.openlineage import create_lineage_event
from tools.impact_analyzer import get_downstream_impact
print('Schemas and tools imported successfully')" 2>&1 || echo "Check for syntax errors"

    # Verify SQLGlot works
    python -c "from sqlglot import lineage; print('SQLGlot lineage available')" 2>&1
  </verify>
  <done>
    Lineage agent imports with 7 tools registered. SQL parser uses SQLGlot for column lineage extraction. OpenLineage tools create compliant events. Impact analyzer provides upstream/downstream traversal via Supabase RPC.
  </done>
</task>

</tasks>

<verification>
1. `cat supabase/migrations/004_lineage_schema.sql | grep "CREATE TABLE"` shows 3 tables
2. Migration includes get_downstream_nodes and get_upstream_nodes functions
3. `cd agents/lineage && python -c "from agent import lineage_agent"` succeeds
4. SQL parser tool correctly parses sample SQL and extracts column dependencies
5. OpenLineage event structure matches specification
6. Impact analyzer tools call Supabase RPC correctly
</verification>

<success_criteria>
- Database schema stores lineage as nodes (dataset, column, job) and edges (derives_from, transforms_to)
- Recursive CTEs enable graph traversal with cycle detection and depth limits
- SQLGlot extracts column-level lineage from SQL with dialect support
- OpenLineage events include ColumnLineageDatasetFacet with transformation details
- Impact analyzer provides both downstream (what breaks) and upstream (root cause) traversal
- Agent follows established Strands SDK pattern with lazy loading proxy
</success_criteria>

<output>
After completion, create `.planning/phases/03-column-level-lineage/03-01-SUMMARY.md`
</output>
